{"pageProps":{"note":{"id":"1y1yaydbzccdy4uu5qkpjt2","title":"Memo (TBD)","desc":"","updated":1667827919523,"created":1667827919523,"custom":{},"fname":"dev.data+ai.pandas.memo2","type":"note","vault":{"fsPath":".","selfContained":true,"name":"Dendron"},"contentHash":"ecfec7238b4d38efa99f99f5ae18e47d","links":[],"anchors":{},"children":[],"parent":"w02ky6rev6fdfd7wml758by","data":{}},"body":"<h1 id=\"memo-tbd\">Memo (TBD)<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#memo-tbd\"></a></h1>\n<blockquote>\n<p>정리 필요</p>\n</blockquote>\n<pre class=\"language-python\"><code class=\"language-python\">   \n<span class=\"token number\">1.</span> Imputation\n\nthreshold <span class=\"token operator\">=</span> <span class=\"token number\">0.7</span>\n\n<span class=\"token comment\"># Dropping columns with missing value rate higher than threshold</span>\ndata <span class=\"token operator\">=</span> data<span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">.</span>columns<span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">.</span>isnull<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&#x3C;</span> threshold<span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># Dropping rows with missing value rate higher than threshold</span>\ndata <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>loc<span class=\"token punctuation\">[</span>data<span class=\"token punctuation\">.</span>isnull<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">&#x3C;</span> threshold<span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># Filling all missing values with 0</span>\ndata <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Filling missing values with medians of the columns</span>\ndata <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">.</span>median<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Max fill function for categorical columns</span>\ndata<span class=\"token punctuation\">[</span><span class=\"token string\">'column_name'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token string\">'column_name'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>value_counts<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>idxmax<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token number\">2.</span> Hangling Outliers\n\n<span class=\"token comment\"># Dropping the outlier rows with standard deviation</span>\nfactor <span class=\"token operator\">=</span> <span class=\"token number\">3</span>\nupper_lim <span class=\"token operator\">=</span> data<span class=\"token punctuation\">[</span><span class=\"token string\">'column'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> data<span class=\"token punctuation\">[</span><span class=\"token string\">'column'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>std<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> factor\nupper_lim <span class=\"token operator\">=</span> data<span class=\"token punctuation\">[</span><span class=\"token string\">'column'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> data<span class=\"token punctuation\">[</span><span class=\"token string\">'column'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>std<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> factor\n\ndata <span class=\"token operator\">=</span> data<span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token string\">'column'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">&#x3C;</span> upper_lim<span class=\"token punctuation\">)</span> <span class=\"token operator\">&#x26;</span> <span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token string\">'column'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">></span> lower_lim<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">]</span>       \n\n<span class=\"token comment\"># Dropping the outlier rows with Percentiles</span>\nupper_lim <span class=\"token operator\">=</span> data<span class=\"token punctuation\">[</span><span class=\"token string\">'column'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>quantile<span class=\"token punctuation\">(</span><span class=\"token number\">.95</span><span class=\"token punctuation\">)</span>\nlower_lim <span class=\"token operator\">=</span> data<span class=\"token punctuation\">[</span><span class=\"token string\">'column'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>quantile<span class=\"token punctuation\">(</span><span class=\"token number\">.05</span><span class=\"token punctuation\">)</span>\n\ndata <span class=\"token operator\">=</span> data<span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token string\">'column'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">&#x3C;</span> upper_lim<span class=\"token punctuation\">)</span> <span class=\"token operator\">&#x26;</span> <span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token string\">'column'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">></span> lower_lim<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token number\">3.</span> Binning\n\n<span class=\"token comment\"># Numerical Binning Example</span>\n\nValue\t   Bin\n<span class=\"token number\">0</span><span class=\"token operator\">-</span><span class=\"token number\">30</span>\t<span class=\"token operator\">-</span><span class=\"token operator\">></span> Low\n<span class=\"token number\">31</span><span class=\"token operator\">-</span><span class=\"token number\">70</span>\t<span class=\"token operator\">-</span><span class=\"token operator\">></span> Mid\n<span class=\"token number\">71</span><span class=\"token operator\">-</span><span class=\"token number\">100</span>\t<span class=\"token operator\">-</span><span class=\"token operator\">></span> High     \n\n<span class=\"token comment\"># Categorical Binning Example</span>\n\nValue\t   Bin\nSpain\t<span class=\"token operator\">-</span><span class=\"token operator\">></span> Europe\nItaly\t<span class=\"token operator\">-</span><span class=\"token operator\">></span> Europe\nChile\t<span class=\"token operator\">-</span><span class=\"token operator\">></span> South America\nBrazil\t<span class=\"token operator\">-</span><span class=\"token operator\">></span> South America      \n\n<span class=\"token comment\"># Numerical Binning Example</span>\n\ndata<span class=\"token punctuation\">[</span><span class=\"token string\">'bin'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>cut<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token string\">'value'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> bins<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">30</span><span class=\"token punctuation\">,</span><span class=\"token number\">70</span><span class=\"token punctuation\">,</span><span class=\"token number\">100</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> labels<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"Low\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"Mid\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"High\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    value   <span class=\"token builtin\">bin</span>\n <span class=\"token number\">0</span>      <span class=\"token number\">2</span>   Low\n <span class=\"token number\">1</span>     <span class=\"token number\">45</span>   Mid\n <span class=\"token number\">2</span>      <span class=\"token number\">7</span>   Low\n <span class=\"token number\">3</span>     <span class=\"token number\">85</span>  High\n <span class=\"token number\">4</span>     <span class=\"token number\">28</span>   Low  \n\n<span class=\"token comment\"># Categorical Binning Example</span>\n\n      Country\n <span class=\"token number\">0</span>      Spain\n <span class=\"token number\">1</span>      Chile\n <span class=\"token number\">2</span>  Australia\n <span class=\"token number\">3</span>      Italy\n <span class=\"token number\">4</span>     Brazil   \n\nconditions <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\n\tdata<span class=\"token punctuation\">[</span><span class=\"token string\">'Country'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>contains<span class=\"token punctuation\">(</span><span class=\"token string\">'Spain'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n\tdata<span class=\"token punctuation\">[</span><span class=\"token string\">'Country'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>contains<span class=\"token punctuation\">(</span><span class=\"token string\">'Italy'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n\tdata<span class=\"token punctuation\">[</span><span class=\"token string\">'Country'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>contains<span class=\"token punctuation\">(</span><span class=\"token string\">'Chile'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n\tdata<span class=\"token punctuation\">[</span><span class=\"token string\">'Country'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>contains<span class=\"token punctuation\">(</span><span class=\"token string\">'Brazil'</span><span class=\"token punctuation\">)</span>  \n<span class=\"token punctuation\">]</span>\n\nchoices <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'Europe'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Europe'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'South America'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'South America'</span><span class=\"token punctuation\">]</span>  \n\ndata<span class=\"token punctuation\">[</span><span class=\"token string\">'Continent'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>select<span class=\"token punctuation\">(</span>conditions<span class=\"token punctuation\">,</span> choices<span class=\"token punctuation\">,</span> default<span class=\"token operator\">=</span><span class=\"token string\">'Other'</span><span class=\"token punctuation\">)</span> \n\n<span class=\"token number\">4.</span> Log Transform\n\n<span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n\n<span class=\"token number\">5.</span> One<span class=\"token operator\">-</span>hot encoding\n\nencoded_columns <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>get_dummies<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token string\">'column'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\ndata <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>encoded_columns<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span><span class=\"token string\">'column'</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token number\">6.</span> Group Operations\n\ndata<span class=\"token punctuation\">.</span>groupby<span class=\"token punctuation\">(</span><span class=\"token string\">'id'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>agg<span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> x<span class=\"token punctuation\">.</span>value_counts<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>index<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Pivot table Pandas Example</span>\n\ndata<span class=\"token punctuation\">.</span>pivot_table<span class=\"token punctuation\">(</span>index<span class=\"token operator\">=</span><span class=\"token string\">'column_to_group'</span><span class=\"token punctuation\">,</span> columns<span class=\"token operator\">=</span><span class=\"token string\">'column_to_encode'</span><span class=\"token punctuation\">,</span> values<span class=\"token operator\">=</span><span class=\"token string\">'aggregation_column'</span><span class=\"token punctuation\">,</span> aggfunc<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">,</span> fill_value <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n\ngrouped <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>groupby<span class=\"token punctuation\">(</span><span class=\"token string\">'column_to_group'</span><span class=\"token punctuation\">)</span>\n\nsums <span class=\"token operator\">=</span> grouped<span class=\"token punctuation\">[</span>sum_cols<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>add_suffix<span class=\"token punctuation\">(</span><span class=\"token string\">'_sum'</span><span class=\"token punctuation\">)</span>\navgs <span class=\"token operator\">=</span> grouped<span class=\"token punctuation\">[</span>mean_cols<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>add_suffix<span class=\"token punctuation\">(</span><span class=\"token string\">'_avg'</span><span class=\"token punctuation\">)</span>\n\nnew_df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>concat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>sums<span class=\"token punctuation\">,</span> avgs<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>  \n\n<span class=\"token number\">7.</span> Feature Split\n\ndata<span class=\"token punctuation\">.</span>name<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\" \"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> x<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\ndata<span class=\"token punctuation\">.</span>name<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\" \"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> x<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> \n\ndata<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\ndata<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\"(\"</span><span class=\"token punctuation\">,</span> n<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> expand<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\")\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> n<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> expand<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token number\">8.</span> Scaling\n\n<span class=\"token comment\"># Normalization</span>\n\ndata <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span><span class=\"token string\">'value'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">45</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">23</span><span class=\"token punctuation\">,</span> <span class=\"token number\">85</span><span class=\"token punctuation\">,</span> <span class=\"token number\">28</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">35</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">12</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>      \n\ndata<span class=\"token punctuation\">[</span><span class=\"token string\">'normalized'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token string\">'value'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">-</span> data<span class=\"token punctuation\">[</span><span class=\"token string\">'value'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span>\n\t<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token string\">'value'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">max</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> data<span class=\"token punctuation\">[</span><span class=\"token string\">'value'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">min</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Standardization</span>\n\ndata<span class=\"token punctuation\">[</span><span class=\"token string\">'standardized'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">[</span><span class=\"token string\">'value'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">-</span> data<span class=\"token punctuation\">[</span><span class=\"token string\">'value'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> \n\tdata<span class=\"token punctuation\">[</span><span class=\"token string\">'value'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>std<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token number\">9.</span> Extracting Date\n\n<span class=\"token keyword\">from</span> datetime <span class=\"token keyword\">import</span> date\n\ndata <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span><span class=\"token string\">'date'</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">[</span><span class=\"token string\">'01-01-2017'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'04-12-2008'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'23-06-1988'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'25-08-1999'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'20-02-1993'</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Transform string to date</span>\ndata<span class=\"token punctuation\">[</span><span class=\"token string\">'date'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>to_datetime<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">.</span>date<span class=\"token punctuation\">,</span> <span class=\"token builtin\">format</span><span class=\"token operator\">=</span><span class=\"token string\">\"%d-%m-%Y\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Extracting Year</span>\ndata<span class=\"token punctuation\">[</span><span class=\"token string\">'month'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> data<span class=\"token punctuation\">[</span><span class=\"token string\">'date'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>year\n\n<span class=\"token comment\"># Extracting Month</span>\ndata<span class=\"token punctuation\">[</span><span class=\"token string\">'month'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> data<span class=\"token punctuation\">[</span><span class=\"token string\">'date'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>month\n\n<span class=\"token comment\"># Extracting passed years since the date </span>\ndata<span class=\"token punctuation\">[</span><span class=\"token string\">'passed_years'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> date<span class=\"token punctuation\">.</span>today<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>year <span class=\"token operator\">-</span> data<span class=\"token punctuation\">[</span><span class=\"token string\">'date'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>year\n\n<span class=\"token comment\"># Extracting passed months since the date</span>\ndata<span class=\"token punctuation\">[</span><span class=\"token string\">'passed_months'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>date<span class=\"token punctuation\">.</span>today<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>year <span class=\"token operator\">-</span> data<span class=\"token punctuation\">[</span><span class=\"token string\">'date'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>year<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">12</span> <span class=\"token operator\">+</span> date<span class=\"token punctuation\">.</span>today<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>month <span class=\"token operator\">-</span> data<span class=\"token punctuation\">[</span><span class=\"token string\">'date'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>month\n\n<span class=\"token comment\"># Extracting the weekday name of the date</span>\ndata<span class=\"token punctuation\">[</span><span class=\"token string\">'day_name'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> data<span class=\"token punctuation\">[</span><span class=\"token string\">'date'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>day_name<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> \n\n<span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">=</span>\n\n<span class=\"token comment\"># Drop columns that have too many missing value </span>\nnull <span class=\"token operator\">=</span> train<span class=\"token punctuation\">.</span>isnull<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ntrain1 <span class=\"token operator\">=</span> train\ntest1 <span class=\"token operator\">=</span> test\ntrain1<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span>columns<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'aaa'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'bbb'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ccc'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\ntest1<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span>columns<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'aaa'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'bbb'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'ccc'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># y, X 설정</span>\ny <span class=\"token operator\">=</span> train1<span class=\"token punctuation\">[</span><span class=\"token string\">'SalePrice'</span><span class=\"token punctuation\">]</span>\nX <span class=\"token operator\">=</span> train1<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span><span class=\"token string\">'SalePrice'</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># boolean field 설정</span>\ntrain1<span class=\"token punctuation\">[</span><span class=\"token string\">'Fence'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>unique<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nfence_map <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token string\">'MnPrv'</span><span class=\"token punctuation\">:</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'GdWo'</span><span class=\"token punctuation\">:</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'GdPrv'</span><span class=\"token punctuation\">:</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'MnWw'</span><span class=\"token punctuation\">:</span><span class=\"token number\">1</span><span class=\"token punctuation\">}</span>\ntrain1<span class=\"token punctuation\">[</span><span class=\"token string\">'Fence'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train1<span class=\"token punctuation\">[</span><span class=\"token string\">'Fence'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>fence_map<span class=\"token punctuation\">)</span>\ntest1<span class=\"token punctuation\">[</span><span class=\"token string\">'Fence'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test1<span class=\"token punctuation\">[</span><span class=\"token string\">'Fence'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>fence_map<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># null 처리</span>\ntrain1<span class=\"token punctuation\">[</span><span class=\"token string\">'Fence'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train1<span class=\"token punctuation\">[</span><span class=\"token string\">'Fence'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>     \ntest1<span class=\"token punctuation\">[</span><span class=\"token string\">'Fence'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test1<span class=\"token punctuation\">[</span><span class=\"token string\">'Fence'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n\ntrain1<span class=\"token punctuation\">[</span><span class=\"token string\">'GarageCond'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>value_counts<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ntrain1<span class=\"token punctuation\">[</span><span class=\"token string\">'GarageCond'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train1<span class=\"token punctuation\">[</span><span class=\"token string\">'GarageCond'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span><span class=\"token string\">'TA'</span><span class=\"token punctuation\">)</span>\ntest1<span class=\"token punctuation\">[</span><span class=\"token string\">'GarageCond'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> test1<span class=\"token punctuation\">[</span><span class=\"token string\">'GarageCond'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span><span class=\"token string\">'TA'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 숫자를 문자열로 변환</span>\ntrain1<span class=\"token punctuation\">[</span><span class=\"token string\">'MoSold'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train1<span class=\"token punctuation\">[</span><span class=\"token string\">'MoSold'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 컬럼의 값의 개수</span>\ntest<span class=\"token punctuation\">[</span><span class=\"token string\">'MSZoning'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>value_counts<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 컬럼 두 개를 하나로 합치기(Merge)</span>\ntrain1<span class=\"token punctuation\">[</span><span class=\"token string\">'Condition'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> train1<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> x<span class=\"token punctuation\">[</span><span class=\"token string\">'Condition1'</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>pd<span class=\"token punctuation\">.</span>isnull<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">[</span><span class=\"token string\">'Condition2'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">else</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">[</span><span class=\"token string\">'Condition1'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token string\">'-'</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">[</span>'Condition2<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\ntrain1<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Condition1'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Condition2'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> inplace<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span> \n     \n<span class=\"token operator\">==</span><span class=\"token operator\">==</span><span class=\"token operator\">=</span> \n\n<span class=\"token keyword\">def</span> <span class=\"token function\">date_preprocessing</span><span class=\"token punctuation\">(</span>dataframe<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    df <span class=\"token operator\">=</span> dataframe<span class=\"token punctuation\">.</span>copy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    df<span class=\"token punctuation\">[</span><span class=\"token string\">'일자'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>to_datetime<span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">[</span><span class=\"token string\">'일자'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    df<span class=\"token punctuation\">[</span><span class=\"token string\">'년도'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> df<span class=\"token punctuation\">[</span><span class=\"token string\">'일자'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>year\n    df<span class=\"token punctuation\">[</span><span class=\"token string\">'월'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> df<span class=\"token punctuation\">[</span><span class=\"token string\">'일자'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>month\n    df<span class=\"token punctuation\">[</span><span class=\"token string\">'일'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> df<span class=\"token punctuation\">[</span><span class=\"token string\">'일자'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>day\n    df<span class=\"token punctuation\">[</span><span class=\"token string\">'주'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> df<span class=\"token punctuation\">[</span><span class=\"token string\">'일자'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>dt<span class=\"token punctuation\">.</span>weekday\n    <span class=\"token keyword\">return</span> df   \n</code></pre>","noteIndex":{"id":"rfaecb1r4pxpahsrighqpfi","title":"Dev","desc":"","updated":1666489926104,"created":1666489926104,"custom":{"nav_order":0,"permalink":"/"},"fname":"dev","type":"note","vault":{"fsPath":".","selfContained":true,"name":"Dendron"},"contentHash":"5f3d9b993bc1c60c0e10119b00a45c49","links":[],"anchors":{},"children":["vmcgt1bw13lwsobet50r3vl","pj0dbesw2qm5j1tub9f34pg","e40hlh2wukm75vo4t8r9c7p","7xwnx64er01irhu8wg1q5zm","4buyekecqhzdg87aqxmh1rz","n1xmefdyaaztqb8wmsmqtjj","d8p9jq81rc0pfbbuzz7prah","yq2839iijurmzkrwkqwo9ps","51sfhirev9l2r8bef9utfb9","xuw6kyksesfaatsmt3gctyi","njc2zpmxz8izls7ogwdj20h","d3ma1d2r59fhejrl6bn9g0e","tgd9pt1fu1j4ejm4g09vlx4","5jlkrg4hx6dpy5tr55grkh6","ockg1gb78gpshwty5zjmvue","owsm2ti22dslhpk9oduhhku","52x2zgp7jpygai1h0jpv0t8","2d5oqog2rsdfdogne54tq9t"],"parent":null,"data":{},"body":""},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true,"enableSelfContainedVaults":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":".","selfContained":true,"name":"Dendron"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"task","dateFormat":"y.MM.dd","addBehavior":"asOwnDomain","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"taskCompleteStatus":["done","x"],"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableFullHierarchyNoteTitle":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["dev","about"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Golbang Hacker","description":"Personal Knowledge Space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"search","assetsPrefix":"/pks-publish","siteUrl":"https://b2sdev.github.io","theme":"dark","siteFaviconPath":"favicon.ico","siteIndex":"dev"}}},"__N_SSG":true}